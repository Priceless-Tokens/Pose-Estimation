{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This programs gives an output of the x,y,z coordinates and visibility as a CSV file, of 34 point on the body, for each frame of the video. (Only cells in \"Program for downloading the x,y,z coordinates as csv\" needs to be run to get this output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dependencies and importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "video1 = \"video1.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the Video File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video1) #Creating the object of the VideoCapture and read the input file\n",
    "  \n",
    "\n",
    "if not cap.isOpened(): # Give a error message\n",
    "    print(\"Error opening Video File.\")\n",
    "try:\n",
    "    while True: # Read the entire file until it is completed \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame',frame) # Display the resulting frame\n",
    "\n",
    "        if cv2.waitKey(24) & 0xFF == ord('q'): # Press Q on keyboard to exit\n",
    "            break\n",
    "\n",
    "        # if frame is read correctly, ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't retrieve frame - stream may have ended. Exiting..\")\n",
    "            break\n",
    "except:\n",
    "    print(\"Video has ended.\")\n",
    "\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # Closes all the frames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video1) #Creating the object of the VideoCapture and read the input file\n",
    "  \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    if not cap.isOpened(): # Give a error message\n",
    "        print(\"Error opening Video File.\")\n",
    "    try:\n",
    "        while True: # Read the entire file until it is completed \n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "            ##print(results)\n",
    "        \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )         \n",
    "            \n",
    "            cv2.imshow('frame',image) # Display the resulting frame\n",
    "\n",
    "            if cv2.waitKey(24) & 0xFF == ord('q'): # Press Q on keyboard to exit\n",
    "                break\n",
    "\n",
    "            # if frame is read correctly, ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't retrieve frame - stream may have ended. Exiting..\")\n",
    "                break\n",
    "    except:\n",
    "        print(\"Video has ended.\")\n",
    "\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() # Closes all the frames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Points in the body](mediapipe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows which joints are connected to each other\n",
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program for downloading the x,y,z coordinates as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has ended.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video1) #Creating the object of the VideoCapture and read the input file\n",
    "\n",
    "  \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    if not cap.isOpened(): # Give a error message\n",
    "        print(\"Error opening Video File.\")\n",
    "    try:\n",
    "        list1=[]\n",
    "\n",
    "        while True: # Read the entire file until it is completed \n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "        \n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "            ##print(results)\n",
    "        \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                list1.append(landmarks)\n",
    "                #print(landmarks)\n",
    "            except:\n",
    "                pass            \n",
    "            \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    ) \n",
    "            \n",
    "            cv2.imshow('frame',image) # Display the resulting frame\n",
    "\n",
    "            if cv2.waitKey(24) & 0xFF == ord('q'): # Press Q on keyboard to exit\n",
    "                break\n",
    "\n",
    "            # if frame is read correctly, ret is True\n",
    "            if not ret:\n",
    "                print(\"Can't retrieve frame - stream may have ended. Exiting..\")\n",
    "                break\n",
    "    except:\n",
    "        print(\"Video has ended.\")\n",
    "\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows() # Closes all the frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(list1)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [f\"Frame{i}\" for i in range(len(list1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"nose,left eye (inner),left eye,left eye (outer),right eye (inner),right eye,right eye (outer),left ear,right ear,mouth (left),mouth (right),left shoulder,right shoulder,left elbow,right elbow,left wrist,right wrist,left pinky,right pinky,left index,right index,left thumb,right thumb,left hip,right hip,left knee,right knee,left ankle,right ankle,left heel,right heel,left foot index,right foot index\"\n",
    "columns = str1.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(arr, index= index, columns=columns)\n",
    "df.to_csv(\"Data_per_frame.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
